name: Daily Data Capture for

on:
  schedule:
    - cron: '35 7 * * *'
  workflow_dispatch:

jobs:
  data_capture:
    runs-on: ubuntu-latest
    env:
      AIR_QUALITY_API: ${{ secrets.AIR_QUALITY_API }}
      
    steps:
      - uses: actions/checkout@v4  # Checks out the code repository

      - name: Install Miniconda
        run: |
          wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
          bash miniconda.sh -b -p $HOME/miniconda
          echo "$HOME/miniconda/bin" >> $GITHUB_PATH
          source $HOME/miniconda/bin/activate

      - name: Create conda environment
        run: |
          conda create --name airquality python=3.8 -y
          conda activate airquality
          conda install -c conda-forge fbprophet pandas altair streamlit -y
          pip install -r requirements.txt

      - name: Run data_capture.py
        run: |  # Executes the script with error handling
          source $HOME/miniconda/bin/activate airquality
          python data_capture.py || (echo "Error running data_capture.py" && exit 1)
          
      - name: List Files
        run: ls -R

      - name: Add and commit CSV file
        run: |
          git config user.email "brownpandadev7@gmail.com"
          git config user.name "foxy-dev1"
          git add air_quality_data.csv
          git commit -m "Add generated CSV file"
          git push origin main
